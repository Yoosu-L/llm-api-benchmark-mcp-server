[project]
name = "llm-api-benchmark-mcp-server"
version = "0.1.0"
description = "Runs a throughput benchmark for LLM APIs, measuring generation speed, prompt throughput, and Time To First Token (TTFT) under various concurrency levels."
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "mcp[cli]>=1.9.3",
    "numpy>=2.3.1",
    "openai>=1.90.0",
    "requests>=2.32.4",
]
